{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hong Kong Weather data Preparation & Data Quality check\n",
    "\n",
    "Here I aggregate 38 datasets coming from different observatory for daily Temperature, Humidity and Rainfall data. For each dataset, I check the number and the percentage of invalid observations (value of \\*\\*\\*).\n",
    "\n",
    "After aggregating, a global dataset by the information is created, so that we have **three global datasets** in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary modules\n",
    "import pandas as pd  # type: ignore\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import numpy as np # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Hong Kong Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Data Downloaded from HK Data Gov website\n",
    "# CSV File list in 0_Data directory:\n",
    "list_files = glob.glob(\"../0_Data/Temperature/*.csv\")\n",
    "\n",
    "# Aggregated Data templete:\n",
    "Agg_Data = pd.DataFrame()\n",
    "Data_summary = pd.DataFrame()\n",
    "\n",
    "for Data_by_dist in list_files:\n",
    "    \n",
    "    Max_region=pd.read_csv(Data_by_dist, \n",
    "                       sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "    # LMMAXT_HKP_: Full Data before any filtering\n",
    "    LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "    LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "    \n",
    "    # Data Quality indicators:\n",
    "    Obs_summary = pd.DataFrame({'Dist': [Data_by_dist.split(\"Data/Temperature/\")[1].split(\"_\")[1]],\n",
    "                                'NObs_Dist': [LMMAXT_HKP_.shape[0]],\n",
    "                                'NObs_Flagged': [LMMAXT_HKP_.loc[LMMAXT_HKP_['Flag']==\"#\"].shape[0]],\n",
    "                                'NObs_Starred': [LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"***\"].shape[0]],\n",
    "                                'NObs_Str_Shrp': [LMMAXT_HKP_.loc[(LMMAXT_HKP_['value']==\"***\")&(LMMAXT_HKP_['Flag']==\"#\")].shape[0]],                          \n",
    "                                'NObs_2007': LMMAXT_HKP_.loc[LMMAXT_HKP_['year']=='2007'].shape[0],\n",
    "                                'NObs_St_or_2007': LMMAXT_HKP_.loc[(LMMAXT_HKP_['year']=='2007')|(LMMAXT_HKP_['value']==\"***\")].shape[0]\n",
    "                                })\n",
    "   \n",
    "    Obs_summary['Starred_Pct(%)'] = round(100*Obs_summary['NObs_Starred']/Obs_summary['NObs_Dist'],2)\n",
    "    Obs_summary['Tot_Purge_Pct(%)'] = round(100*Obs_summary['NObs_St_or_2007']/Obs_summary['NObs_Dist'],2)\n",
    "        \n",
    "    ## Data Filter ##\n",
    "    # LMMAXT_HKP_2: Filtered Data\n",
    "    # F1: Delete the last 3 lines:\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_.iloc[:-3]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'month'] = LMMAXT_HKP_2['month'].values.astype(int)\n",
    "    LMMAXT_HKP_2.loc[:,'day'] = LMMAXT_HKP_2['day'].values.astype(int)\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['value']!=\"***\"]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'value'] = LMMAXT_HKP_2['value'].values.astype(float)\n",
    "\n",
    "    # F2: Delete data of 2007 since incomplete (only from october)\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['year']!='2007']\n",
    "    \n",
    "    # Put in the Observatory Name:\n",
    "    LMMAXT_HKP_2['Dist'] = Data_by_dist.split(\"Data/Temperature/\")[1].split(\"_\")[1]\n",
    "\n",
    "    # Date parsing \n",
    "    LMMAXT_HKP_date = pd.to_datetime(LMMAXT_HKP_2[['year','month', 'day']])\n",
    "    #LMMAXT_HKP_date = LMMAXT_HKP_date.dt.dayofyear\n",
    "    \n",
    "    # Concatenate parsed date + Table \n",
    "    # LMMAXT_HKP_3: Concatenated Data\n",
    "    LMMAXT_HKP_3 = pd.concat([LMMAXT_HKP_date, \n",
    "                              LMMAXT_HKP_2[['Dist','year','value', 'Flag']]],\n",
    "            axis = 1)\n",
    "    LMMAXT_HKP_3 = LMMAXT_HKP_3.rename(columns = {0: \"Date\"})\n",
    "    \n",
    "    \n",
    "    # Information on the observed period by Observatory:\n",
    "    Obs_summary['StartDate'] = LMMAXT_HKP_date.min()\n",
    "    Obs_summary['EndDate'] = LMMAXT_HKP_date.max()\n",
    "    \n",
    "    Data_summary = pd.concat([Data_summary, Obs_summary], axis = 0)\n",
    "    \n",
    "    Agg_Data = pd.concat([Agg_Data, LMMAXT_HKP_3], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the lines are completed, computing the percentage of null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*Agg_Data.loc[Agg_Data['value'].isna()!=False].shape[0]/Agg_Data.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations before filtering (From all observatories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362334\n"
     ]
    }
   ],
   "source": [
    "total_obs = Data_summary['NObs_Dist'].sum()\n",
    "print(total_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations after filtering on 2007 and the starred observations (From all observatories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349513"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agg_Data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the total number of observations, given that we applied 2 filters and 3 lines deletion containing some suppementary informations at the end of each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(349513)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_obs - Data_summary['NObs_St_or_2007'].sum() -(3*38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution by observatories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Observatory   NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "0         HKO  49006                     13.53                    144\n",
      "1         SHA  14764                      4.07                     41\n",
      "2         LFS  14399                      3.97                     40\n",
      "3         TKL  13425                      3.71                     38\n",
      "4         HKS  12999                      3.59                     37\n",
      "   Observatory  NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "33         TY1  5298                      1.46                     15\n",
      "34          TW  5201                      1.44                     15\n",
      "35         SE1  3730                      1.03                     11\n",
      "36         YLP  3637                      1.00                     11\n",
      "37         CWB  2285                      0.63                      7\n"
     ]
    }
   ],
   "source": [
    "Data_Composition = pd.DataFrame({\n",
    "    'Observatory':Data_summary['Dist'].values,\n",
    "    'NObs':Data_summary['NObs_Dist'].values,\n",
    "    'Percentage(%)To_TotalOBS':round((Data_summary['NObs_Dist']/total_obs)*100,2),\n",
    "    'ObservedPeriod(#Year)':[np.ceil(td/np.timedelta64(1, 'D')).astype(int) for td in (Data_summary['EndDate']-Data_summary['StartDate'])/(30*12)] \n",
    "})\n",
    "\n",
    "Data_Composition.sort_values(by=['Percentage(%)To_TotalOBS','ObservedPeriod(#Year)'], \n",
    "                             ascending = False,\n",
    "                             inplace = True)\n",
    "Data_Composition.reset_index(inplace=True, drop = True)\n",
    "print(Data_Composition.head())\n",
    "print(Data_Composition.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2\n"
     ]
    }
   ],
   "source": [
    "print(round(Data_Composition['ObservedPeriod(#Year)'].mean(),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the observatory which logged Temperature data for the longest period in Hong Kong is the one in Hong Kong Observatory in Tsim Sha Tsui area (HKO, for 144 years). It composes of about 14% of the total dataset. The shortest observated period is given by Clear Water Bay Observatory (CWB, for 7 years). The mean value of the observed period over 38 observatories is 27 years.\n",
    "\n",
    "When we look for the percentage of the invalid lines (containing \\*\\*\\* value), the observatory providing the highest data quality issue is Ngong Ping Observatory (5.5%). The highest invalid data ratio (5.5%) is still relatively low. It goes down to 0% (only one line deleted) when it comes to Hong Kong Observatory which is the most historical observatory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dist  NObs_Dist  NObs_Starred  NObs_St_or_2007  Starred_Pct(%)  \\\n",
      "0  NGP       7855           432              788            5.50   \n",
      "0  SEK      10320           439              754            4.25   \n",
      "0  WGL      12968           520              885            4.01   \n",
      "0  JKB      12147           412              777            3.39   \n",
      "0  TPO       8710           293              658            3.36   \n",
      "\n",
      "   Tot_Purge_Pct(%)  \n",
      "0             10.03  \n",
      "0              7.31  \n",
      "0              6.82  \n",
      "0              6.40  \n",
      "0              7.55  \n",
      "...\n",
      "  Dist  NObs_Dist  NObs_Starred  NObs_St_or_2007  Starred_Pct(%)  \\\n",
      "0  TY1       5298             2                2            0.04   \n",
      "0  SSH       7520             3              368            0.04   \n",
      "0   TW       5201             2                2            0.04   \n",
      "0  WTS       5816             1                1            0.02   \n",
      "0  HKO      49006             1              366            0.00   \n",
      "\n",
      "   Tot_Purge_Pct(%)  \n",
      "0              0.04  \n",
      "0              4.89  \n",
      "0              0.04  \n",
      "0              0.02  \n",
      "0              0.75  \n"
     ]
    }
   ],
   "source": [
    "print(Data_summary.iloc[:,[0,1,3,6,7,8]].sort_values(by='Starred_Pct(%)', ascending=False).head())\n",
    "print(\"...\")\n",
    "print(Data_summary.iloc[:,[0,1,3,6,7,8]].sort_values(by='Starred_Pct(%)', ascending=False).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without access to the definition of these flags, I have used all numerical values including the ones flagged to '#' in Data Completeness column if it contains a normal numerical value other than '***'.\n",
    "\n",
    "As of Temperature dataset, the percentage of observations filled with '***' takes less than 1% for 71% of 38 Hong Kong districts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*Data_summary.loc[Data_summary['Starred_Pct(%)']<1].shape[0]/Data_summary.shape[0],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "if not os.path.exists(treated_data_rep):\n",
    "    os.makedirs(treated_data_rep)\n",
    "Agg_Data.to_pickle(treated_data_rep+\"Temperature_AGG.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
