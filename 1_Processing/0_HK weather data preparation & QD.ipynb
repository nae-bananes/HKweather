{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hong Kong Weather data Preparation & Data Quality check\n",
    "\n",
    "Here I aggregate 38 datasets coming from different observatory for daily Temperature, Humidity and Rainfall data. For each dataset, I check the number and the percentage of invalid observations (value of \\*\\*\\*).\n",
    "\n",
    "After aggregating, a global dataset by the information is created, so that we have **three global datasets** in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary modules\n",
    "import pandas as pd  # type: ignore\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import numpy as np # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Hong Kong Maximal Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public Data Downloaded from HK Data Gov website\n",
    "# CSV File list in 0_Data directory:\n",
    "list_files = glob.glob(\"../0_Data/HK/Temperature/*.csv\")\n",
    "\n",
    "# Aggregated Data templete:\n",
    "Agg_Data = pd.DataFrame()\n",
    "Data_summary = pd.DataFrame()\n",
    "\n",
    "for Data_by_dist in list_files:\n",
    "    \n",
    "    Max_region=pd.read_csv(Data_by_dist, \n",
    "                       sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "    # LMMAXT_HKP_: Full Data before any filtering\n",
    "    LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "    LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "    \n",
    "    # Data Quality indicators:\n",
    "    Obs_summary = pd.DataFrame({'Dist': [Data_by_dist.split(\"Data/Temperature/\")[1].split(\"_\")[1]],\n",
    "                                'NObs_Dist': [LMMAXT_HKP_.shape[0]],\n",
    "                                'NObs_Flagged': [LMMAXT_HKP_.loc[LMMAXT_HKP_['Flag']==\"#\"].shape[0]],\n",
    "                                'NObs_Starred': [LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"***\"].shape[0]],\n",
    "                                'NObs_Str_Flagged': [LMMAXT_HKP_.loc[(LMMAXT_HKP_['value']==\"***\")&(LMMAXT_HKP_['Flag']==\"#\")].shape[0]]                          \n",
    "                                #'NObs_2007': LMMAXT_HKP_.loc[LMMAXT_HKP_['year']=='2007'].shape[0],\n",
    "                                #'NObs_St_or_2007': LMMAXT_HKP_.loc[(LMMAXT_HKP_['year']=='2007')|(LMMAXT_HKP_['value']==\"***\")].shape[0]\n",
    "                                })\n",
    "   \n",
    "    Obs_summary['Starred_Pct(%)'] = round(100*Obs_summary['NObs_Starred']/Obs_summary['NObs_Dist'],2)\n",
    "    #Obs_summary['Tot_Purge_Pct(%)'] = round(100*Obs_summary['NObs_St_or_2007']/Obs_summary['NObs_Dist'],2)\n",
    "        \n",
    "    ## Data Filter ##\n",
    "    # LMMAXT_HKP_2: Filtered Data\n",
    "    # F1: Delete the last 3 lines:\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_.iloc[:-3]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'month'] = LMMAXT_HKP_2['month'].values.astype(int)\n",
    "    LMMAXT_HKP_2.loc[:,'day'] = LMMAXT_HKP_2['day'].values.astype(int)\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['value']!=\"***\"]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'value'] = LMMAXT_HKP_2['value'].values.astype(float)\n",
    "\n",
    "    # F2: Delete data of 2007 since incomplete (only from october)\n",
    "    #LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['year']!='2007']\n",
    "    \n",
    "    # Insert the Observatory Name:\n",
    "    LMMAXT_HKP_2['Dist'] = Data_by_dist.split(\"Data/Temperature/\")[1].split(\"_\")[1]\n",
    "\n",
    "    # Date parsing \n",
    "    LMMAXT_HKP_date = pd.to_datetime(LMMAXT_HKP_2[['year','month', 'day']])\n",
    "    #LMMAXT_HKP_date = LMMAXT_HKP_date.dt.dayofyear\n",
    "    \n",
    "    # Concatenate parsed date + Table \n",
    "    # LMMAXT_HKP_3: Concatenated Data\n",
    "    LMMAXT_HKP_3 = pd.concat([LMMAXT_HKP_date, \n",
    "                              LMMAXT_HKP_2[['Dist','year','value', 'Flag']]],\n",
    "            axis = 1)\n",
    "    LMMAXT_HKP_3 = LMMAXT_HKP_3.rename(columns = {0: \"Date\"})\n",
    "    \n",
    "    \n",
    "    # Information on the observed period by Observatory:\n",
    "    Obs_summary['StartDate'] = LMMAXT_HKP_date.min()\n",
    "    Obs_summary['EndDate'] = LMMAXT_HKP_date.max()\n",
    "    \n",
    "    Data_summary = pd.concat([Data_summary, Obs_summary], axis = 0)\n",
    "    \n",
    "    Agg_Data = pd.concat([Agg_Data, LMMAXT_HKP_3], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all the lines are completed, computing the percentage of null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*Agg_Data.loc[Agg_Data['value'].isna()!=False].shape[0]/Agg_Data.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations before filtering (From all observatories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362334\n"
     ]
    }
   ],
   "source": [
    "total_obs = Data_summary['NObs_Dist'].sum()\n",
    "print(total_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of observations after filtering the starred observations (From all observatories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358380"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agg_Data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the total number of observations, given that we applied 2 filters and 3 lines deletion containing some suppementary informations at the end of each table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(358380)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_obs -Data_summary['NObs_Starred'].sum() -(3*38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution by observatories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Observatory   NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "0         HKO  49006                     13.53                    144\n",
      "1         SHA  14764                      4.07                     41\n",
      "2         LFS  14399                      3.97                     40\n",
      "3         TKL  13425                      3.71                     38\n",
      "4         HKS  12999                      3.59                     37\n",
      "   Observatory  NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "33         TY1  5298                      1.46                     15\n",
      "34          TW  5201                      1.44                     15\n",
      "35         SE1  3730                      1.03                     11\n",
      "36         YLP  3637                      1.00                     11\n",
      "37         CWB  2285                      0.63                      7\n"
     ]
    }
   ],
   "source": [
    "Data_Composition = pd.DataFrame({\n",
    "    'Observatory':Data_summary['Dist'].values,\n",
    "    'NObs':Data_summary['NObs_Dist'].values,\n",
    "    'Percentage(%)To_TotalOBS':round((Data_summary['NObs_Dist']/total_obs)*100,2),\n",
    "    'ObservedPeriod(#Year)':[np.ceil(td/np.timedelta64(1, 'D')).astype(int) for td in (Data_summary['EndDate']-Data_summary['StartDate'])/(30*12)] \n",
    "})\n",
    "\n",
    "Data_Composition.sort_values(by=['Percentage(%)To_TotalOBS','ObservedPeriod(#Year)'], \n",
    "                             ascending = False,\n",
    "                             inplace = True)\n",
    "Data_Composition.reset_index(inplace=True, drop = True)\n",
    "print(Data_Composition.head())\n",
    "print(Data_Composition.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2\n"
     ]
    }
   ],
   "source": [
    "print(round(Data_Composition['ObservedPeriod(#Year)'].mean(),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the observatory which logged Temperature data for the longest period in Hong Kong is the one in Hong Kong Observatory in Tsim Sha Tsui area (HKO, for 144 years). It composes of about 14% of the total dataset. The shortest observated period is given by Clear Water Bay Observatory (CWB, for 7 years). The mean value of the observed period over 38 observatories is 27 years.\n",
    "\n",
    "When we look for the percentage of the invalid lines (containing \\*\\*\\* value), the observatory providing the highest data quality issue is Ngong Ping Observatory (5.5%). The highest invalid data ratio (5.5%) is still relatively low. It goes down to 0% (only one line deleted) when it comes to Hong Kong Observatory which is the most historical observatory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dist  NObs_Dist  NObs_Starred  Starred_Pct(%)\n",
      "0  NGP       7855           432            5.50\n",
      "0  SEK      10320           439            4.25\n",
      "0  WGL      12968           520            4.01\n",
      "0  JKB      12147           412            3.39\n",
      "0  TPO       8710           293            3.36\n",
      "...\n",
      "  Dist  NObs_Dist  NObs_Starred  Starred_Pct(%)\n",
      "0  TY1       5298             2            0.04\n",
      "0  SSH       7520             3            0.04\n",
      "0   TW       5201             2            0.04\n",
      "0  WTS       5816             1            0.02\n",
      "0  HKO      49006             1            0.00\n"
     ]
    }
   ],
   "source": [
    "print(Data_summary.iloc[:,[0,1,3,5]].sort_values(by='Starred_Pct(%)', ascending=False).head())\n",
    "print(\"...\")\n",
    "print(Data_summary.iloc[:,[0,1,3,5]].sort_values(by='Starred_Pct(%)', ascending=False).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without access to the definition of these flags, I have used all numerical values including the ones flagged to '#' in Data Completeness column if it contains a normal numerical value other than '***'.\n",
    "\n",
    "As of Temperature dataset, the percentage of observations filled with '***' takes less than 1% for 71% of 38 Hong Kong districts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*Data_summary.loc[Data_summary['Starred_Pct(%)']<1].shape[0]/Data_summary.shape[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the aggregated Temperature data in Wrangled directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "if not os.path.exists(treated_data_rep):\n",
    "    os.makedirs(treated_data_rep)\n",
    "Agg_Data.to_pickle(treated_data_rep+\"Temperature_AGG.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Hong Kong Mean Humidity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  value Flag\n",
      "0  1947    1.0  1.0   85.0    C\n",
      "1  1947    1.0  2.0   86.0    C\n",
      "2  1947    1.0  3.0   84.0    C\n",
      "3  1947    1.0  4.0   85.0    C\n",
      "4  1947    1.0  5.0   85.0    C\n",
      "                          year  month   day  value Flag\n",
      "28547                     2025    2.0  27.0   76.0    C\n",
      "28548                     2025    2.0  28.0   77.0    C\n",
      "28549     *** 沒有數據/unavailable    NaN   NaN    NaN  NaN\n",
      "28550  # 數據不完整/data incomplete    NaN   NaN    NaN  NaN\n",
      "28551     C 數據完整/data Complete    NaN   NaN    NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# Public Data Downloaded from HK Data Gov website\n",
    "# CSV File list in 0_Data directory:\n",
    "list_files = glob.glob(\"../0_Data/HK/Humidity/*.csv\")\n",
    "    \n",
    "Max_region=pd.read_csv(list_files[0], \n",
    "                    sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "# LMMAXT_HKP_: Full Data before any filtering\n",
    "LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "\n",
    "print(LMMAXT_HKP_.head())\n",
    "print(LMMAXT_HKP_.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of data seems exactly the same as Max Temperature dataset. Therefore, we proceed the wrangling with the same code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregated Data templete:\n",
    "Agg_Data = pd.DataFrame()\n",
    "Data_summary = pd.DataFrame()\n",
    "\n",
    "for Data_by_dist in list_files:\n",
    "    \n",
    "    Max_region=pd.read_csv(Data_by_dist, \n",
    "                       sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "    # LMMAXT_HKP_: Full Data before any filtering\n",
    "    LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "    LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "    \n",
    "    # Data Quality indicators:\n",
    "    Obs_summary = pd.DataFrame({'Dist': [Data_by_dist.split(\"Data/Humidity/\")[1].split(\"_\")[1]],\n",
    "                                'NObs_Dist': [LMMAXT_HKP_.shape[0]],\n",
    "                                'NObs_Flagged': [LMMAXT_HKP_.loc[LMMAXT_HKP_['Flag']==\"#\"].shape[0]],\n",
    "                                'NObs_Starred': [LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"***\"].shape[0]],\n",
    "                                'NObs_Str_Flagged': [LMMAXT_HKP_.loc[(LMMAXT_HKP_['value']==\"***\")&(LMMAXT_HKP_['Flag']==\"#\")].shape[0]]                          \n",
    "                                #'NObs_2007': LMMAXT_HKP_.loc[LMMAXT_HKP_['year']=='2007'].shape[0],\n",
    "                                #'NObs_St_or_2007': LMMAXT_HKP_.loc[(LMMAXT_HKP_['year']=='2007')|(LMMAXT_HKP_['value']==\"***\")].shape[0]\n",
    "                                })\n",
    "   \n",
    "    Obs_summary['Starred_Pct(%)'] = round(100*Obs_summary['NObs_Starred']/Obs_summary['NObs_Dist'],2)\n",
    "    #Obs_summary['Tot_Purge_Pct(%)'] = round(100*Obs_summary['NObs_St_or_2007']/Obs_summary['NObs_Dist'],2)\n",
    "        \n",
    "    ## Data Filter ##\n",
    "    # LMMAXT_HKP_2: Filtered Data\n",
    "    # F1: Delete the last 3 lines:\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_.iloc[:-3]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'month'] = LMMAXT_HKP_2['month'].values.astype(int)\n",
    "    LMMAXT_HKP_2.loc[:,'day'] = LMMAXT_HKP_2['day'].values.astype(int)\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['value']!=\"***\"]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    LMMAXT_HKP_2.loc[:,'value'] = LMMAXT_HKP_2['value'].values.astype(float)\n",
    "    \n",
    "    # Insert the Observatory Name:\n",
    "    LMMAXT_HKP_2['Dist'] = Data_by_dist.split(\"Data/Humidity/\")[1].split(\"_\")[1]\n",
    "\n",
    "    # Date parsing \n",
    "    LMMAXT_HKP_date = pd.to_datetime(LMMAXT_HKP_2[['year','month', 'day']])\n",
    "    #LMMAXT_HKP_date = LMMAXT_HKP_date.dt.dayofyear\n",
    "    \n",
    "    # Concatenate parsed date + Table \n",
    "    # LMMAXT_HKP_3: Concatenated Data\n",
    "    LMMAXT_HKP_3 = pd.concat([LMMAXT_HKP_date, \n",
    "                              LMMAXT_HKP_2[['Dist','year','value', 'Flag']]],\n",
    "            axis = 1)\n",
    "    LMMAXT_HKP_3 = LMMAXT_HKP_3.rename(columns = {0: \"Date\"})\n",
    "    \n",
    "    \n",
    "    # Information on the observed period by Observatory:\n",
    "    Obs_summary['StartDate'] = LMMAXT_HKP_date.min()\n",
    "    Obs_summary['EndDate'] = LMMAXT_HKP_date.max()\n",
    "    \n",
    "    Data_summary = pd.concat([Data_summary, Obs_summary], axis = 0)\n",
    "    \n",
    "    Agg_Data = pd.concat([Agg_Data, LMMAXT_HKP_3], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) NA value percentage (%): 0.0 % \n",
      "\n",
      "(2-1) Total number of observations (From Summary table sum-up): 249419) \n",
      "\n",
      "(2-2) Total number of observations (From Aggregated data number of row counting): 241237 \n",
      "\n",
      "(3) The number of observations after filter application (From Summary table sum-up deducted the # of filtered lines): 241237 \n",
      "\n",
      "(4) Humidity data observed period: \n",
      "\n",
      "  Observatory   NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "0         HKO  28552                     11.45                     80\n",
      "1         SHA  14764                      5.92                     41\n",
      "2         LFS  14399                      5.77                     40\n",
      "3         TKL  13425                      5.38                     38\n",
      "4         HKS  12999                      5.21                     37\n",
      "   Observatory  NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "19         TU1  6637                      2.66                     19\n",
      "20         KSC  6059                      2.43                     17\n",
      "21         TY1  5298                      2.12                     15\n",
      "22          TW  5201                      2.09                     15\n",
      "23         YCT  1068                      0.43                      3\n",
      "\n",
      " (5) Humidity data mean observed period: 29.4 year\n"
     ]
    }
   ],
   "source": [
    "total_obs = Data_summary['NObs_Dist'].sum()\n",
    "Data_Composition = pd.DataFrame({\n",
    "    'Observatory':Data_summary['Dist'].values,\n",
    "    'NObs':Data_summary['NObs_Dist'].values,\n",
    "    'Percentage(%)To_TotalOBS':round((Data_summary['NObs_Dist']/total_obs)*100,2),\n",
    "    'ObservedPeriod(#Year)':[np.ceil(td/np.timedelta64(1, 'D')).astype(int) for td in (Data_summary['EndDate']-Data_summary['StartDate'])/(30*12)] \n",
    "})\n",
    "\n",
    "Data_Composition.sort_values(by=['Percentage(%)To_TotalOBS','ObservedPeriod(#Year)'], \n",
    "                             ascending = False,\n",
    "                             inplace = True)\n",
    "Data_Composition.reset_index(inplace=True, drop = True)\n",
    "\n",
    "print(f\"(1) NA value percentage (%): {round(100*Agg_Data.loc[Agg_Data['value'].isna()!=False].shape[0]/Agg_Data.shape[0],1)} % \\n\")\n",
    "print(f\"(2-1) Total number of observations (From Summary table sum-up): {total_obs}) \\n\")\n",
    "print(f\"(2-2) Total number of observations (From Aggregated data number of row counting): {Agg_Data.shape[0]} \\n\")\n",
    "print(f\"(3) The number of observations after filter application (From Summary table sum-up deducted the # of filtered lines): {total_obs - Data_summary['NObs_Starred'].sum() -(3*24)} \\n\")\n",
    "print(\"(4) Humidity data observed period: \\n\")\n",
    "print(Data_Composition.head())\n",
    "print(Data_Composition.tail())\n",
    "print(f\"\\n (5) Humidity data mean observed period: {round(Data_Composition['ObservedPeriod(#Year)'].mean(),1)} year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Humidity data, the mean observed period of all the observatories is about 29 years, similar to Temperature data but slightly longer. The maximal observed period is 80 years, also for Hong Kong Observatory. \n",
    "\n",
    "In contrary, the percentage of null values (\\*\\*\\*) are higher for Humidity dataset. Its maximal value is observed up to 17% (vs. 5.5% for Temperature dataset). The data quality, at least as of the starred observations, is also very good for the most historical observatory, Hong Kong Observatory. The other observatory which has 0 starred observation is Hong Kong International Airport (HKA).\n",
    "\n",
    "Data Quality in general is worse for Humidity dataset, when it comes to the percentage of observatories having less than 1% of their dataset filled by starred lines. It only counts 50% of all the observatories, in contrary to Temperature dataset (71%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6) Missing values by Observatory: \n",
      "\n",
      "  Dist  NObs_Dist  NObs_Starred  Starred_Pct(%)\n",
      "0  JKB      12147          2101           17.30\n",
      "0  LFS      14399          1857           12.90\n",
      "0  WGL      12968           872            6.72\n",
      "0  SEK      10320           586            5.68\n",
      "0  TKL      13425           580            4.32\n",
      "\n",
      "...\n",
      "\n",
      "  Dist  NObs_Dist  NObs_Starred  Starred_Pct(%)\n",
      "0   TW       5201             8            0.15\n",
      "0  YCT       1068             1            0.09\n",
      "0   KP      11934             9            0.08\n",
      "0  HKO      28552             0            0.00\n",
      "0  HKA      10138             0            0.00\n",
      "\n",
      " (7) Percentage of observatories with less than 1% of missing values: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"(6) Missing values by Observatory: \\n\")\n",
    "print(Data_summary.iloc[:,[0,1,3,5]].sort_values(by='Starred_Pct(%)', ascending=False).head())\n",
    "print(\"\\n...\\n\")\n",
    "print(Data_summary.iloc[:,[0,1,3,5]].sort_values(by='Starred_Pct(%)', ascending=False).tail())\n",
    "print(f\"\\n (7) Percentage of observatories with less than 1% of missing values: {round(100*Data_summary.loc[Data_summary['Starred_Pct(%)']<1].shape[0]/Data_summary.shape[0],0)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the aggregated Humidity data in Wrangled directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "if not os.path.exists(treated_data_rep):\n",
    "    os.makedirs(treated_data_rep)\n",
    "Agg_Data.to_pickle(treated_data_rep+\"Humidity_AGG.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Hong Kong Rainfall Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day value Flag\n",
      "0  2010    4.0  1.0   0.0    C\n",
      "1  2010    4.0  2.0   4.0    C\n",
      "2  2010    4.0  3.0   0.0    C\n",
      "3  2010    4.0  4.0   0.0    #\n",
      "4  2010    4.0  5.0   ***  NaN\n",
      "                         year  month   day value Flag\n",
      "5446                     2025    2.0  27.0   0.0    C\n",
      "5447                     2025    2.0  28.0   0.0    C\n",
      "5448     *** 沒有數據/unavailable    NaN   NaN   NaN  NaN\n",
      "5449  # 數據不完整/data incomplete    NaN   NaN   NaN  NaN\n",
      "5450     C 數據完整/data Complete    NaN   NaN   NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# Public Data Downloaded from HK Data Gov website\n",
    "# CSV File list in 0_Data directory:\n",
    "list_files = glob.glob(\"../0_Data/HK/Rainfall/*.csv\")\n",
    "    \n",
    "Max_region=pd.read_csv(list_files[0], \n",
    "                    sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "# LMMAXT_HKP_: Full Data before any filtering\n",
    "LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "\n",
    "print(LMMAXT_HKP_.head())\n",
    "print(LMMAXT_HKP_.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the same structure. I have to delete 2025 datasets since these are already included in the whole period dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a_supprimer = [x for x in list_files if \"2025\" in x]\n",
    "for files in list_a_supprimer:\n",
    "    os.remove(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Rainfall data, there were some anormal observations with 'Trace' as value. For example, for Hong Kong Observatory Rainfall dataset, there were 6856 observations filled with 'Trace' (14% of the total dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1884</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1884</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12107</th>\n",
       "      <td>1917</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12122</th>\n",
       "      <td>1917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123</th>\n",
       "      <td>1917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48929</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48935</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48936</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48937</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48939</th>\n",
       "      <td>2025</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Trace</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6856 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month   day  value Flag\n",
       "280    1884   12.0   6.0  Trace    C\n",
       "281    1884   12.0   7.0  Trace    C\n",
       "12107  1917    4.0  24.0  Trace    C\n",
       "12122  1917    5.0   9.0  Trace    C\n",
       "12123  1917    5.0  10.0  Trace    C\n",
       "...     ...    ...   ...    ...  ...\n",
       "48929  2025    2.0  15.0  Trace    C\n",
       "48935  2025    2.0  21.0  Trace    C\n",
       "48936  2025    2.0  22.0  Trace    C\n",
       "48937  2025    2.0  23.0  Trace    C\n",
       "48939  2025    2.0  25.0  Trace    C\n",
       "\n",
       "[6856 rows x 5 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_region=pd.read_csv(\"../0_Data/HK/Rainfall/daily_HKO_RF_ALL.csv\", \n",
    "                    sep=\",\", skiprows=3, header = None)\n",
    "LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "print(round(100*LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"Trace\"].shape[0]/LMMAXT_HKP_.shape[0],2))\n",
    "LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"Trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(\"../0_Data/HK/Rainfall/*.csv\")\n",
    "# Aggregated Data templete:\n",
    "Agg_Data = pd.DataFrame()\n",
    "Data_summary = pd.DataFrame()\n",
    "\n",
    "for Data_by_dist in list_files:\n",
    "    \n",
    "    Max_region=pd.read_csv(Data_by_dist, \n",
    "                       sep=\",\", skiprows=3, header = None)\n",
    "\n",
    "    # LMMAXT_HKP_: Full Data before any filtering\n",
    "    LMMAXT_HKP_ = pd.DataFrame(Max_region)\n",
    "    LMMAXT_HKP_.columns = ['year', 'month', 'day', 'value', 'Flag']\n",
    "    \n",
    "    # Data Quality indicators:\n",
    "    Obs_summary = pd.DataFrame({'Dist': [Data_by_dist.split(\"Data/Rainfall/\")[1].split(\"_\")[1]],\n",
    "                                'NObs_Dist': [LMMAXT_HKP_.shape[0]],\n",
    "                                'NObs_Flagged': [LMMAXT_HKP_.loc[LMMAXT_HKP_['Flag']==\"#\"].shape[0]],\n",
    "                                'NObs_Starred': [LMMAXT_HKP_.loc[LMMAXT_HKP_['value']==\"***\"].shape[0]],\n",
    "                                'NObs_Str_Flagged': [LMMAXT_HKP_.loc[(LMMAXT_HKP_['value']==\"***\")&(LMMAXT_HKP_['Flag']==\"#\")].shape[0]],                          \n",
    "                                'NObs_Trace': [LMMAXT_HKP_.loc[LMMAXT_HKP_['value']=='Trace'].shape[0]],\n",
    "                                'NObs_Purged': [LMMAXT_HKP_.loc[(LMMAXT_HKP_['value'].isin([\"***\", \"Trace\"])==True)|((LMMAXT_HKP_['month'].isna()&LMMAXT_HKP_['value'].isna())==True)].shape[0]]\n",
    "                                })\n",
    "   \n",
    "    Obs_summary['Starred_Pct(%)'] = round(100*Obs_summary['NObs_Starred']/Obs_summary['NObs_Dist'],2)\n",
    "    Obs_summary['Tot_Purge_Pct(%)'] = round(100*Obs_summary['NObs_Purged']/Obs_summary['NObs_Dist'],2)\n",
    "        \n",
    "    ## Data Filter ##\n",
    "    # LMMAXT_HKP_2: Filtered Data\n",
    "    # F1: Delete the last lines containing comments:\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_.loc[(LMMAXT_HKP_['month'].isna()&LMMAXT_HKP_['value'].isna())==False]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    \n",
    "    # F2: Delete the starred obs or 'Trace' valued lines:\n",
    "    LMMAXT_HKP_2 = LMMAXT_HKP_2.loc[LMMAXT_HKP_2['value'].isin([\"***\", \"Trace\"])==False]\n",
    "    LMMAXT_HKP_2.reset_index(inplace=True, drop=True) \n",
    "    \n",
    "    LMMAXT_HKP_2.loc[:,'month'] = LMMAXT_HKP_2['month'].values.astype(int)\n",
    "    LMMAXT_HKP_2.loc[:,'day'] = LMMAXT_HKP_2['day'].values.astype(int)\n",
    "    LMMAXT_HKP_2.loc[:,'value'] = LMMAXT_HKP_2['value'].values.astype(float)\n",
    "    \n",
    "    # Insert the Observatory Name:\n",
    "    LMMAXT_HKP_2['Dist'] = Data_by_dist.split(\"Data/Rainfall/\")[1].split(\"_\")[1]\n",
    "\n",
    "    # Date parsing \n",
    "    LMMAXT_HKP_date = pd.to_datetime(LMMAXT_HKP_2[['year','month', 'day']])\n",
    "    #LMMAXT_HKP_date = LMMAXT_HKP_date.dt.dayofyear\n",
    "    \n",
    "    # Concatenate parsed date + Table \n",
    "    # LMMAXT_HKP_3: Concatenated Data\n",
    "    LMMAXT_HKP_3 = pd.concat([LMMAXT_HKP_date, \n",
    "                              LMMAXT_HKP_2[['Dist','year','value', 'Flag']]],\n",
    "            axis = 1)\n",
    "    LMMAXT_HKP_3 = LMMAXT_HKP_3.rename(columns = {0: \"Date\"})\n",
    "    \n",
    "    \n",
    "    # Information on the observed period by Observatory:\n",
    "    Obs_summary['StartDate'] = LMMAXT_HKP_date.min()\n",
    "    Obs_summary['EndDate'] = LMMAXT_HKP_date.max()\n",
    "    \n",
    "    Data_summary = pd.concat([Data_summary, Obs_summary], axis = 0)\n",
    "    \n",
    "    Agg_Data = pd.concat([Agg_Data, LMMAXT_HKP_3], axis = 0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While looking into the Data Filtering summaries, I realize that 'Trace' values are observed only in Hong Kong Observatory dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dist</th>\n",
       "      <th>NObs_Dist</th>\n",
       "      <th>NObs_Flagged</th>\n",
       "      <th>NObs_Starred</th>\n",
       "      <th>NObs_Str_Flagged</th>\n",
       "      <th>NObs_Trace</th>\n",
       "      <th>NObs_Purged</th>\n",
       "      <th>Starred_Pct(%)</th>\n",
       "      <th>Tot_Purge_Pct(%)</th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSP</td>\n",
       "      <td>5451</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KSC</td>\n",
       "      <td>6059</td>\n",
       "      <td>190</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCH</td>\n",
       "      <td>12025</td>\n",
       "      <td>140</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1992-04-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TYW</td>\n",
       "      <td>10747</td>\n",
       "      <td>283</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1995-10-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEK</td>\n",
       "      <td>10320</td>\n",
       "      <td>92</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1996-12-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPH</td>\n",
       "      <td>8220</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2002-09-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VP1</td>\n",
       "      <td>7642</td>\n",
       "      <td>130</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2004-04-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WGL</td>\n",
       "      <td>12968</td>\n",
       "      <td>378</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>704</td>\n",
       "      <td>5.41</td>\n",
       "      <td>5.43</td>\n",
       "      <td>1989-09-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TMS</td>\n",
       "      <td>10258</td>\n",
       "      <td>165</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>589</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.74</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JKB</td>\n",
       "      <td>12116</td>\n",
       "      <td>155</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>446</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1992-01-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TWN</td>\n",
       "      <td>6882</td>\n",
       "      <td>47</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2006-05-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKW</td>\n",
       "      <td>6364</td>\n",
       "      <td>99</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HKO</td>\n",
       "      <td>48947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6856</td>\n",
       "      <td>6861</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.02</td>\n",
       "      <td>1884-03-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LFS</td>\n",
       "      <td>14399</td>\n",
       "      <td>243</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1985-10-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TKL</td>\n",
       "      <td>14368</td>\n",
       "      <td>234</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>513</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1985-11-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WLP</td>\n",
       "      <td>7033</td>\n",
       "      <td>53</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2005-12-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SE</td>\n",
       "      <td>5541</td>\n",
       "      <td>27</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.29</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHA</td>\n",
       "      <td>14764</td>\n",
       "      <td>232</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1984-10-02</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SSH</td>\n",
       "      <td>7520</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2004-08-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PEN</td>\n",
       "      <td>7581</td>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2004-06-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLC</td>\n",
       "      <td>11750</td>\n",
       "      <td>272</td>\n",
       "      <td>507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TU1</td>\n",
       "      <td>6637</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KP</td>\n",
       "      <td>11934</td>\n",
       "      <td>144</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1992-07-01</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TC</td>\n",
       "      <td>9955</td>\n",
       "      <td>117</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1997-12-18</td>\n",
       "      <td>2025-02-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dist  NObs_Dist  NObs_Flagged  NObs_Starred  NObs_Str_Flagged  NObs_Trace  \\\n",
       "0  SSP       5451            70            44                 0           0   \n",
       "0  KSC       6059           190           109                 0           0   \n",
       "0  CCH      12025           140           204                 0           0   \n",
       "0  TYW      10747           283           229                 0           0   \n",
       "0  SEK      10320            92           493                 0           0   \n",
       "0  CPH       8220            21            10                 0           0   \n",
       "0  VP1       7642           130           141                 0           0   \n",
       "0  WGL      12968           378           701                 0           0   \n",
       "0  TMS      10258           165           586                 0           0   \n",
       "0  JKB      12116           155           443                 0           0   \n",
       "0  TWN       6882            47            17                 0           0   \n",
       "0  SKW       6364            99            38                 0           0   \n",
       "0  HKO      48947             0             1                 0        6856   \n",
       "0  LFS      14399           243           186                 0           0   \n",
       "0  TKL      14368           234           510                 0           0   \n",
       "0  WLP       7033            53            73                 0           0   \n",
       "0   SE       5541            27           124                 0           0   \n",
       "0  SHA      14764           232           266                 0           0   \n",
       "0  SSH       7520            21             4                 0           0   \n",
       "0  PEN       7581            64            26                 0           0   \n",
       "0  PLC      11750           272           507                 0           0   \n",
       "0  TU1       6637            37            27                 0           0   \n",
       "0   KP      11934           144            11                 0           0   \n",
       "0   TC       9955           117           163                 0           0   \n",
       "\n",
       "   NObs_Purged  Starred_Pct(%)  Tot_Purge_Pct(%)  StartDate    EndDate  \n",
       "0           47            0.81              0.86 2010-04-01 2025-02-28  \n",
       "0          112            1.80              1.85 2008-08-01 2025-02-28  \n",
       "0          207            1.70              1.72 1992-04-01 2025-02-28  \n",
       "0          232            2.13              2.16 1995-10-01 2025-02-28  \n",
       "0          496            4.78              4.81 1996-12-01 2025-02-28  \n",
       "0           13            0.12              0.16 2002-09-01 2025-02-28  \n",
       "0          144            1.85              1.88 2004-04-01 2025-02-28  \n",
       "0          704            5.41              5.43 1989-09-01 2025-02-28  \n",
       "0          589            5.71              5.74 1997-02-01 2025-02-28  \n",
       "0          446            3.66              3.68 1992-01-01 2025-02-28  \n",
       "0           20            0.25              0.29 2006-05-01 2025-02-28  \n",
       "0           41            0.60              0.64 2007-10-01 2025-02-28  \n",
       "0         6861            0.00             14.02 1884-03-01 2025-02-28  \n",
       "0          189            1.29              1.31 1985-10-01 2025-02-28  \n",
       "0          513            3.55              3.57 1985-11-01 2025-02-28  \n",
       "0           76            1.04              1.08 2005-12-01 2025-02-28  \n",
       "0          127            2.24              2.29 2010-04-01 2025-02-28  \n",
       "0          269            1.80              1.82 1984-10-02 2025-02-28  \n",
       "0            7            0.05              0.09 2004-08-01 2025-02-28  \n",
       "0           29            0.34              0.38 2004-06-01 2025-02-28  \n",
       "0          510            4.31              4.34 1993-01-01 2025-02-28  \n",
       "0           30            0.41              0.45 2007-01-01 2025-02-28  \n",
       "0           14            0.09              0.12 1992-07-01 2025-02-28  \n",
       "0          166            1.64              1.67 1997-12-18 2025-02-28  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) NA value percentage (%): 0.0 % \n",
      "\n",
      "(2-1) Total number of observations (From Summary table sum-up): 269481) \n",
      "\n",
      "(2-2) Total number of observations (From Aggregated data number of row counting): 257639 \n",
      "\n",
      "(3) The number of observations after filter application (From Summary table sum-up deducted the # of filtered lines): 257639 \n",
      "\n",
      "(4) Rainfall data observed period: \n",
      "\n",
      "  Observatory   NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "0         HKO  48947                     18.16                    144\n",
      "1         SHA  14764                      5.48                     41\n",
      "2         LFS  14399                      5.34                     40\n",
      "3         TKL  14368                      5.33                     40\n",
      "4         WGL  12968                      4.81                     37\n",
      "   Observatory  NObs  Percentage(%)To_TotalOBS  ObservedPeriod(#Year)\n",
      "19         TU1  6637                      2.46                     19\n",
      "20         SKW  6364                      2.36                     18\n",
      "21         KSC  6059                      2.25                     17\n",
      "22          SE  5541                      2.06                     16\n",
      "23         SSP  5451                      2.02                     16\n",
      "\n",
      " (5) Rainfall data mean observed period: 32.0 year\n"
     ]
    }
   ],
   "source": [
    "total_obs = Data_summary['NObs_Dist'].sum()\n",
    "Data_Composition = pd.DataFrame({\n",
    "    'Observatory':Data_summary['Dist'].values,\n",
    "    'NObs':Data_summary['NObs_Dist'].values,\n",
    "    'Percentage(%)To_TotalOBS':round((Data_summary['NObs_Dist']/total_obs)*100,2),\n",
    "    'ObservedPeriod(#Year)':[np.ceil(td/np.timedelta64(1, 'D')).astype(int) for td in (Data_summary['EndDate']-Data_summary['StartDate'])/(30*12)] \n",
    "})\n",
    "\n",
    "Data_Composition.sort_values(by=['Percentage(%)To_TotalOBS','ObservedPeriod(#Year)'], \n",
    "                             ascending = False,\n",
    "                             inplace = True)\n",
    "Data_Composition.reset_index(inplace=True, drop = True)\n",
    "\n",
    "print(f\"(1) NA value percentage (%): {round(100*Agg_Data.loc[Agg_Data['value'].isna()!=False].shape[0]/Agg_Data.shape[0],1)} % \\n\")\n",
    "print(f\"(2-1) Total number of observations (From Summary table sum-up): {total_obs}) \\n\")\n",
    "print(f\"(2-2) Total number of observations (From Aggregated data number of row counting): {Agg_Data.shape[0]} \\n\")\n",
    "print(f\"(3) The number of observations after filter application (From Summary table sum-up deducted the # of filtered lines): {total_obs - Data_summary['NObs_Purged'].sum()} \\n\")\n",
    "print(\"(4) Rainfall data observed period: \\n\")\n",
    "print(Data_Composition.head())\n",
    "print(Data_Composition.tail())\n",
    "print(f\"\\n (5) Rainfall data mean observed period: {round(Data_Composition['ObservedPeriod(#Year)'].mean(),1)} year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Rainfall data, the longest observed period is 144 years for Hong Kong Observatory, same as for Temperature data. Mean period of observation is slightly longer, 32 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6) Missing values by Observatory: \n",
      "\n",
      "  Dist  NObs_Dist  NObs_Starred  NObs_Trace  Starred_Pct(%)  Tot_Purge_Pct(%)\n",
      "0  HKO      48947             1        6856            0.00             14.02\n",
      "0  TMS      10258           586           0            5.71              5.74\n",
      "0  WGL      12968           701           0            5.41              5.43\n",
      "0  SEK      10320           493           0            4.78              4.81\n",
      "0  PLC      11750           507           0            4.31              4.34\n",
      "\n",
      "...\n",
      "\n",
      "  Dist  NObs_Dist  NObs_Starred  NObs_Trace  Starred_Pct(%)  Tot_Purge_Pct(%)\n",
      "0  PEN       7581            26           0            0.34              0.38\n",
      "0  TWN       6882            17           0            0.25              0.29\n",
      "0  CPH       8220            10           0            0.12              0.16\n",
      "0   KP      11934            11           0            0.09              0.12\n",
      "0  SSH       7520             4           0            0.05              0.09\n",
      "\n",
      " (7) Percentage of observatories with less than 1% of missing values: 33.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"(6) Missing values by Observatory: \\n\")\n",
    "print(Data_summary.iloc[:,[0,1,3,5,7,8]].sort_values(by='Tot_Purge_Pct(%)', ascending=False).head())\n",
    "print(\"\\n...\\n\")\n",
    "print(Data_summary.iloc[:,[0,1,3,5,7,8]].sort_values(by='Tot_Purge_Pct(%)', ascending=False).tail())\n",
    "print(f\"\\n (7) Percentage of observatories with less than 1% of missing values: {round(100*Data_summary.loc[Data_summary['Tot_Purge_Pct(%)']<1].shape[0]/Data_summary.shape[0],0)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Rainfall dataset, the overall missing value portion is similar to two other datasets, around 5% for the maximal case (Tai Mo Shan dataset (TMS)). The only difference is the lines containing 'Trace' value in Hong Kong Observatory dataset. \n",
    "\n",
    "Now we save the aggregated Rainfall dataset in Wrangled directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "if not os.path.exists(treated_data_rep):\n",
    "    os.makedirs(treated_data_rep)\n",
    "Agg_Data.to_pickle(treated_data_rep+\"Rainfall_AGG.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Creation of an aggregated dataset with the daily average value of three variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "Temperature_AGG = pd.read_pickle(treated_data_rep+\"Temperature_AGG.pkl\")\n",
    "Rainfall_AGG = pd.read_pickle(treated_data_rep+\"Rainfall_AGG.pkl\")\n",
    "Humidity_AGG = pd.read_pickle(treated_data_rep+\"Humidity_AGG.pkl\")\n",
    "Temperature_AGG.set_index([\"Date\", \"Dist\"], inplace = True)\n",
    "Rainfall_AGG.set_index([\"Date\", \"Dist\"], inplace = True)\n",
    "Humidity_AGG.set_index([\"Date\", \"Dist\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_temp =Temperature_AGG[['value']].join(Rainfall_AGG[['value']], \n",
    "                                          on = [\"Date\", \"Dist\"], \n",
    "                                          rsuffix = \"RR\").join(\n",
    "                                              Humidity_AGG[['value']], \n",
    "                                              on = [\"Date\", \"Dist\"],\n",
    "                                              rsuffix = \"UM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Average over observatories:\n",
    "AGG_temp.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del AGG_temp['Dist']\n",
    "AGG_temp = AGG_temp.groupby('Date').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG_temp.columns = ['TX', 'RR', 'UM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_data_rep = r'../0_Data/wrangled/' \n",
    "if not os.path.exists(treated_data_rep):\n",
    "    os.makedirs(treated_data_rep)\n",
    "AGG_temp.to_pickle(treated_data_rep+\"HKDaily_AGG.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HKweather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
